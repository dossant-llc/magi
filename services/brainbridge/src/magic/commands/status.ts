/**
 * mAGIc Status Command
 * Shows system status and health checks
 */

import * as fs from 'fs/promises';
import * as path from 'path';
import { aiConfig } from '../../config/ai-config';
import { getMemoriesPath } from '../../utils/magi-paths';

export async function statusCommand() {
  const config = aiConfig.getConfig();
  console.log(`ğŸ¤– mAGIc System Status (${config.provider.toUpperCase()})`);
  console.log('â•'.repeat(50));
  
  // Check AI Provider
  console.log(`ğŸ”„ Checking ${config.provider.toUpperCase()} connection...`);
  
  if (config.provider === 'ollama') {
    await checkOllamaStatus(config);
  } else if (config.provider === 'openai') {
    await checkOpenAIStatus(config);
  } else if (config.provider === 'gemini') {
    await checkGeminiStatus(config);
  } else {
    console.log(`âŒ Unknown provider: ${config.provider}`);
  }
  
  // Check memory directories using correct path
  console.log('\nğŸ“ Memory Storage:');
  const memoriesDir = getMemoriesPath();
  const privacyLevels = ['public', 'team', 'personal', 'private', 'sensitive'];
  
  let totalFiles = 0;
  for (const level of privacyLevels) {
    try {
      const dir = path.join(memoriesDir, level);
      const files = await fs.readdir(dir);
      const mdFiles = files.filter(f => f.endsWith('.md')).length;
      totalFiles += mdFiles;
      console.log(`  ${level.padEnd(9)}: ${mdFiles} memories`);
    } catch (error) {
      console.log(`  ${level.padEnd(9)}: Directory not found`);
    }
  }
  
  console.log(`  ${'Total'.padEnd(9)}: ${totalFiles} memories`);
  
  // Check provider-specific index status
  console.log('\nğŸ” Vector Index:');
  try {
    const indexPath = aiConfig.getIndexPath(path.join(memoriesDir, 'embeddings'));
    const embeddingsFile = path.join(indexPath, 'embeddings.txt');
    
    try {
      const stats = await fs.stat(embeddingsFile);
      console.log(`  âœ… ${config.provider.toUpperCase()} embeddings index found`);
      console.log(`     Size: ${(stats.size / 1024).toFixed(1)}KB`);
      console.log(`     Modified: ${stats.mtime.toLocaleDateString()}`);
    } catch (error) {
      console.log(`  âŒ ${config.provider.toUpperCase()} embeddings index not found`);
      console.log('     Run: magic index to create initial index');
    }
  } catch (error) {
    console.log('  âŒ Index path error');
    console.log('     Run: magic index to create initial index');
  }
  
  console.log('\nğŸ¯ Quick Actions:');
  console.log('  magic save "your content here" - Save new knowledge');
  console.log('  magic query "your question" - Ask about your knowledge');  
  console.log('  magic index - Build/rebuild vector index');
}

async function checkOllamaStatus(config: any) {
  try {
    const { Ollama } = require('ollama');
    const ollama = new Ollama({ host: config.ollamaHost ? `http://${config.ollamaHost}:${config.ollamaPort}` : 'http://127.0.0.1:11434' });
    
    const models = await ollama.list();
    const chatModel = models.models.find(m => m.name.includes(config.chatModel.split(':')[0]));
    const embedModel = models.models.find(m => m.name.includes(config.embeddingModel.split(':')[0]));
    
    console.log('âœ… Ollama: Connected');
    console.log(`  ğŸ“Š Chat Model (${config.chatModel}): ${chatModel ? 'âœ… Available' : 'âŒ Missing'}`);
    console.log(`  ğŸ§  Embed Model (${config.embeddingModel}): ${embedModel ? 'âœ… Available' : 'âŒ Missing'}`);
    
    if (chatModel) {
      console.log(`     Size: ${(chatModel.size / (1024*1024*1024)).toFixed(1)}GB`);
      console.log(`     Modified: ${new Date(chatModel.modified_at).toLocaleDateString()}`);
    }
    
  } catch (error) {
    console.log('âŒ Ollama: Not accessible');
    console.log('   Make sure Ollama is running: ollama serve');
  }
}

async function checkOpenAIStatus(config: any) {
  try {
    console.log('âœ… OpenAI: Configured');
    console.log(`  ğŸ“Š Chat Model: ${config.chatModel}`);
    console.log(`  ğŸ§  Embed Model: ${config.embeddingModel}`);
    
    if (config.openaiApiKey) {
      const maskedKey = `${config.openaiApiKey.substring(0, 8)}...${config.openaiApiKey.substring(config.openaiApiKey.length - 4)}`;
      console.log(`  ğŸ”‘ API Key: ${maskedKey}`);
    } else {
      console.log('  âŒ API Key: Not configured');
      console.log('     Set OPENAI_API_KEY in .env file');
    }
    
  } catch (error) {
    console.log('âŒ OpenAI: Configuration error');
    console.log(`   Error: ${error.message}`);
  }
}

async function checkGeminiStatus(config: any) {
  try {
    console.log('âœ… Gemini: Configured');
    console.log(`  ğŸ“Š Chat Model: Not available (embedding-only provider)`);
    console.log(`  ğŸ§  Embed Model: ${config.embeddingModel}`);
    
    if (config.geminiApiKey) {
      const maskedKey = `${config.geminiApiKey.substring(0, 8)}...${config.geminiApiKey.substring(config.geminiApiKey.length - 4)}`;
      console.log(`  ğŸ”‘ API Key: ${maskedKey}`);
      console.log(`  âš ï¸  Free Tier: 5 requests/minute, 25 requests/day`);
    } else {
      console.log('  âŒ API Key: Not configured');
      console.log('     Set GEMINI_API_KEY or GOOGLE_API_KEY in .env file');
      console.log('     Get your free key at: https://aistudio.google.com/app/apikey');
    }
    
  } catch (error) {
    console.log('âŒ Gemini: Configuration error');
    console.log(`   Error: ${error.message}`);
  }
}